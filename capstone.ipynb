{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "dfTrees=pd.read_csv('Public_Owned_Trees.csv')\n",
    "\n",
    "print(dfTrees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHomes=pd.read_excel('columbushomes.xlsx')\n",
    "dfHomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split function that wil seperate site address into Number, road, type, and direction with the same attribute labels as the trees data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_address(df, address_col):\n",
    "    # Ensure all data in address_col are strings\n",
    "    df[address_col] = df[address_col].astype(str)\n",
    "\n",
    "    # Remove rows where address contains a hyphen\n",
    "    df = df[~df[address_col].str.contains('-')]\n",
    "\n",
    "    # Split the address into parts\n",
    "    df[['ADDR_NUM', 'Rest']] = df[address_col].str.split(' ', 1, expand=True)\n",
    "    df['STR_TYPE'] = df['Rest'].str[-2:]\n",
    "    df['Rest'] = df['Rest'].str[:-3]\n",
    "\n",
    "    # Replace NaN values in 'Rest' with an empty string\n",
    "    df['Rest'] = df['Rest'].fillna('')\n",
    "\n",
    "    # If the rest of the address starts with a known direction, extract it\n",
    "    df.loc[df['Rest'].str.startswith(('N ', 'S ', 'E ', 'W ')), 'STR_PRE_DIR'] = df['Rest'].str[:1]\n",
    "    df.loc[df['Rest'].str.startswith(('N ', 'S ', 'E ', 'W ')), 'Rest'] = df['Rest'].str[2:]\n",
    "\n",
    "    # The rest of the address is the street name\n",
    "    df['STR_NAME'] = df['Rest']\n",
    "    df = df.drop(columns='Rest')\n",
    "\n",
    "    # Convert the house numbers to integers, coercing errors to NaN\n",
    "    df['ADDR_NUM'] = pd.to_numeric(df['ADDR_NUM'], errors='coerce')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split street address into street number and street name and street type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'Sale Price' is 0 or more than 600000\n",
    "dfHomes= dfHomes[(dfHomes['Sale Price'] > 0) & (dfHomes['Sale Price'] < 600000)]\n",
    "dfHomes = split_address(dfHomes, 'Site Address')\n",
    "\n",
    "# Save the processed dataframe to a new CSV file\n",
    "dfHomes.to_csv('cbusHomes.csv')\n",
    "\n",
    "dfHomes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove STR_SUF_DIR\tHEIGHT LIFE_STAGE1\n",
    "RETIRED>1972\n",
    "PLANTING_DATE<2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Change homes from xlsx to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHomes.to_csv('dfHomes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will remove all building types that are not dwellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for rows where 'Building Type' is 'Dwelling'\n",
    "dfHomes= dfHomes[dfHomes['Building Type'] == 'Dwelling']\n",
    "# Drop rows with a value in 'Site Addr Num Hi'\n",
    "dfHomes= dfHomes[dfHomes['Site Addr Num Hi'].isna()]\n",
    "# Display the first few rows of the filtered dataframe\n",
    "dfHomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHomes.to_csv('cbusHomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns STR_SUF_DIR,\tHEIGHT, LIFE_STAGE1, and Change format of Retired and Planted from 1970/01/01 00:00:00+00 to 1970\n",
    "#filter Retired after 1972 and planting date after 2013\n",
    "\n",
    "\n",
    "dfTrees=dfTrees.drop(columns=['STR_SUF_DIR', 'HEIGHT', 'LIFE_STAGE1'])\n",
    "dfTrees['PLANTING_DATE']=dfTrees['PLANTING_DATE'].str[:4]\n",
    "dfTrees['RETIRED']=dfTrees['RETIRED'].str[:4]\n",
    "dfTrees=dfTrees[dfTrees['PLANTING_DATE']<'2013']\n",
    "dfTrees=dfTrees[dfTrees['RETIRED']>'1972']\n",
    "dfTrees.to_csv('cbusTrees.csv')\n",
    "dfTrees.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for trees within a 2 block area of the house on the same street\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHomes=pd.read_csv('cbusHomes.csv')\n",
    "dfTrees=pd.read_csv('cbusTrees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify all houses with a tree or directly adjacent to a tree. Count the total numbers of trees that each house has near it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns in dfHomes to match dfTrees\n",
    "dfHomes.rename(columns={'Site Addr Num Lo': 'ADDR_NUM', \n",
    "                            'Site Addr Direction': 'STR_PRE_DIR', \n",
    "                            'Site Addr Street': 'STR_NAME', \n",
    "                            'Site Addr Suffix 1': 'STR_TYPE'}, inplace=True)\n",
    "\n",
    "# Drop NaN values from the 'ADDR_NUM' column in both dataframes\n",
    "dfHomes.dropna(subset=['ADDR_NUM'], inplace=True)\n",
    "dfTrees.dropna(subset=['ADDR_NUM'], inplace=True)\n",
    "\n",
    "# Convert 'ADDR_NUM' to integers in both dataframes\n",
    "dfHomes['ADDR_NUM'] = dfHomes['ADDR_NUM'].astype(int)\n",
    "dfTrees['ADDR_NUM'] = dfTrees['ADDR_NUM'].astype(int)\n",
    "\n",
    "# Create dataframes for adjacent houses\n",
    "df_trees_left = dfTrees.copy()\n",
    "df_trees_left['ADDR_NUM'] -= 2\n",
    "\n",
    "df_trees_right = dfTrees.copy()\n",
    "df_trees_right['ADDR_NUM'] += 2\n",
    "\n",
    "# Concatenate tree and adjacent house dataframes\n",
    "df_adjacent = pd.concat([dfTrees, df_trees_left, df_trees_right])\n",
    "\n",
    "# Merge with home data\n",
    "df_merged = pd.merge(dfHomes, df_adjacent, on=['ADDR_NUM','STR_NAME','STR_TYPE','STR_PRE_DIR'], how='inner')\n",
    "\n",
    "# Group by address and count trees\n",
    "tree_counts = df_merged.groupby(['ADDR_NUM','STR_NAME','STR_TYPE','STR_PRE_DIR']).size().reset_index(name='treeCount')\n",
    "\n",
    "# Merge tree counts back to original home dataframe\n",
    "df_final = pd.merge(dfHomes, tree_counts, on=['ADDR_NUM','STR_NAME','STR_TYPE','STR_PRE_DIR'], how='left')\n",
    "\n",
    "# Create a multi-index based on the address fields\n",
    "tree_counts.set_index(['ADDR_NUM','STR_NAME','STR_TYPE','STR_PRE_DIR'], inplace=True)\n",
    "\n",
    "# Map the tree counts to dfHomes dataframe using the multi-index\n",
    "df_final['treeCount'] = df_final.set_index(['ADDR_NUM','STR_NAME','STR_TYPE','STR_PRE_DIR']).index.map(tree_counts['treeCount'])\n",
    "\n",
    "# Fill NA values with 0 and convert to int\n",
    "df_final['treeCount'] = df_final['treeCount'].fillna(0).astype(int)\n",
    "\n",
    "# Export to CSV\n",
    "df_final.to_csv('cbusHomesTrees.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataframe\n",
    "df_final.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now begin looking at the impact of public trees on houses home value.  However, we will control for the following factors through ultiple regression analysis. \n",
    "Public trees: 'treeCount'\n",
    "Zip code: 'Zip Code'\n",
    "Neighborhood: 'Neighborhood'\n",
    "Year built: 'Year Built'\n",
    "Year remodeled: 'Year Remodel'\n",
    "Grade: 'Grade'\n",
    "Condition: 'Condition'\n",
    "Bedrooms: 'Bedrooms'\n",
    "Full baths: 'Full Baths'\n",
    "Half baths: 'Half Baths'\n",
    "Basement: 'Basement'\n",
    "Attic: 'Attic'\n",
    "Heat and A/C: 'Heat and A/C'\n",
    "Area finished above grade: 'Area Finished Above Grade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Select columns for regression analysis\n",
    "df_regression = df_final[['Mkt Value-Total', 'treeCount', 'Zip Code', 'Neighborhood', 'Year Built', 'Year Remodel', \n",
    "                          'Grade', 'Condition', 'Bedrooms', 'Full Baths', 'Half Baths', 'Basement', 'Attic', \n",
    "                          'Heat and A/C', 'Area Finished Above Grade']].copy()\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables (one-hot encoding)\n",
    "df_regression = pd.get_dummies(df_regression, drop_first=True)\n",
    "\n",
    "# Replace NaN values with the mean\n",
    "df_regression.fillna(df_regression.mean(), inplace=True)\n",
    "\n",
    "# Define dependent variable (y) and independent variables (X)\n",
    "y = df_regression['Mkt Value-Total']\n",
    "X = df_regression.drop('Mkt Value-Total', axis=1)\n",
    "\n",
    "# Split the data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# Calculate the root mean square error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\n",
    "\n",
    "# Results\n",
    "rmse, coefficients.sort_values(by='Coefficient', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the RME was pretty horrible...so let's take a look at some other factors. We will start by using the feature importance method via a random forest to compute the importance of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Convert the importances into one-dimensional 1darray with corresponding df column names as axis labels\n",
    "f_importances = pd.Series(importances, X.columns)\n",
    "\n",
    "# Sort the array in descending order of the importances\n",
    "f_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "f_importances.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5131/2826148202.py:4: DtypeWarning: Columns (7,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfFinal=pd.read_csv('cbusHomesTrees.csv')\n"
     ]
    }
   ],
   "source": [
    "# remove Unnamed: 0\tParcel Number\t\tSite Addr Num Hi\t\t\t\tSite Addr Suffix 2\t\t\t\t\t\t\t\tPrior TIF Mkt Value-Impr\t\t\t\t\t\t\t\tStyle\tExterior Wall\t\t\t\t\t\t\t\tAddl Fixtures\tTotal Fixtures\t\t\t\tFireplace Openings\tFireplace Stacks\t\tArea Finished Below Grade\tArea Rec Room\tArea Unfinished\tAttached Garage Spaces\tBasement Garage Spaces\tCarport Spaces\n",
    "#from dfFinal\n",
    "import pandas as pd\n",
    "dfFinal=pd.read_csv('cbusHomesTrees.csv')\n",
    "dfFinal.drop(columns=['Unnamed: 0','Parcel Number','Site Addr Num Hi','Site Addr Suffix 2','Prior TIF Mkt Value-Impr','Style','Exterior Wall','Addl Fixtures','Total Fixtures','Fireplace Openings','Fireplace Stacks','Area Finished Below Grade','Area Rec Room','Area Unfinished','Attached Garage Spaces','Basement Garage Spaces','Carport Spaces'], inplace=True)\n",
    "dfFinal.to_csv('dfFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point i realized how many neighborhoods dont have trees so we will remove those neighborhoods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADDR_NUM</th>\n",
       "      <th>STR_PRE_DIR</th>\n",
       "      <th>STR_NAME</th>\n",
       "      <th>STR_TYPE</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Historic District</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Mkt Value-Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Family Rooms</th>\n",
       "      <th>Dining Rooms</th>\n",
       "      <th>Full Baths</th>\n",
       "      <th>Half Baths</th>\n",
       "      <th>Basement</th>\n",
       "      <th>Attic</th>\n",
       "      <th>Heat and A/C</th>\n",
       "      <th>Area Finished Above Grade</th>\n",
       "      <th>treeCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>W</td>\n",
       "      <td>PACEMONT</td>\n",
       "      <td>RD</td>\n",
       "      <td>40.0270</td>\n",
       "      <td>-83.0170</td>\n",
       "      <td>43202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3801.0</td>\n",
       "      <td>181700</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FULL BASEMENT</td>\n",
       "      <td>NO ATTIC</td>\n",
       "      <td>HEAT/AIR CON</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRANKLIN</td>\n",
       "      <td>AV</td>\n",
       "      <td>39.9616</td>\n",
       "      <td>-82.9578</td>\n",
       "      <td>43205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>520100</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FULL BASEMENT</td>\n",
       "      <td>NO ATTIC</td>\n",
       "      <td>HEAT/AIR CON</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110</td>\n",
       "      <td>N</td>\n",
       "      <td>CASSADY</td>\n",
       "      <td>AV</td>\n",
       "      <td>39.9936</td>\n",
       "      <td>-82.9296</td>\n",
       "      <td>43219.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>190900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WALSH</td>\n",
       "      <td>AV</td>\n",
       "      <td>39.9481</td>\n",
       "      <td>-83.0388</td>\n",
       "      <td>43223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9403.0</td>\n",
       "      <td>54100</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FULL BASEMENT</td>\n",
       "      <td>NO ATTIC</td>\n",
       "      <td>HEAT/AIR CON</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITTIER</td>\n",
       "      <td>ST</td>\n",
       "      <td>39.9442</td>\n",
       "      <td>-82.9794</td>\n",
       "      <td>43206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>117000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FULL BASEMENT</td>\n",
       "      <td>NO ATTIC</td>\n",
       "      <td>HEAT/AIR CON</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADDR_NUM STR_PRE_DIR  STR_NAME STR_TYPE  Latitude  Longitude  Zip Code  \\\n",
       "0        86           W  PACEMONT       RD   40.0270   -83.0170   43202.0   \n",
       "1      1570         NaN  FRANKLIN       AV   39.9616   -82.9578   43205.0   \n",
       "2      1110           N   CASSADY       AV   39.9936   -82.9296   43219.0   \n",
       "6      1502         NaN     WALSH       AV   39.9481   -83.0388   43223.0   \n",
       "7       652         NaN  WHITTIER       ST   39.9442   -82.9794   43206.0   \n",
       "\n",
       "  Historic District  Neighborhood  Mkt Value-Total  ...  Bedrooms  \\\n",
       "0               NaN        3801.0           181700  ...       2.0   \n",
       "1               NaN        1201.0           520100  ...       3.0   \n",
       "2               NaN        5300.0           190900  ...       NaN   \n",
       "6               NaN        9403.0            54100  ...       3.0   \n",
       "7               NaN        1600.0           117000  ...       3.0   \n",
       "\n",
       "  Family Rooms  Dining Rooms Full Baths  Half Baths       Basement     Attic  \\\n",
       "0          NaN           1.0        1.0         NaN  FULL BASEMENT  NO ATTIC   \n",
       "1          NaN           NaN        2.0         1.0  FULL BASEMENT  NO ATTIC   \n",
       "2          2.0           0.0        1.0         NaN            NaN       NaN   \n",
       "6          1.0           1.0        1.0         1.0  FULL BASEMENT  NO ATTIC   \n",
       "7          NaN           1.0        1.0         1.0  FULL BASEMENT  NO ATTIC   \n",
       "\n",
       "   Heat and A/C Area Finished Above Grade  treeCount  \n",
       "0  HEAT/AIR CON                    1063.0          0  \n",
       "1  HEAT/AIR CON                    1869.0          0  \n",
       "2           NaN                    2278.0          0  \n",
       "6  HEAT/AIR CON                    1008.0          0  \n",
       "7  HEAT/AIR CON                    1280.0          0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find zip codes with total tree count 0\n",
    "zip_codes_with_zero_trees = dfFinal.groupby('Zip Code')['treeCount'].sum()\n",
    "zip_codes_with_zero_trees = zip_codes_with_zero_trees[zip_codes_with_zero_trees == 0].index.tolist()\n",
    "\n",
    "# Drop rows with those zip codes\n",
    "dfFinal_filtered = dfFinal[~dfFinal['Zip Code'].isin(zip_codes_with_zero_trees)]\n",
    "dfFinal.to_csv('dfFinal_filtered.csv')\n",
    "dfFinal_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43923119f7024e3ca56b57bdc4103af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d050e047c6460b9144b415c51f59e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29ec340069c4d1587924d107bd26ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bd05f6d4b24b9b9363d18ab557fada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ydata_profiling  as ydp\n",
    "# create a profiling report of df_final\n",
    "profile = ydp.ProfileReport(dfFinal)\n",
    "profile.to_file(\"df_final.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importances.to_csv('feature_importances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use the top 10 feartures to apply a random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Select top 10 features\u001b[39;00m\n\u001b[1;32m      4\u001b[0m selected_features \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mArea Finished Above Grade\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAttic_NO ATTIC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNeighborhood\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mZip Code\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mYear Built\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mHeat and A/C_HEAT/AIR CON\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mYear Remodel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGrade_C\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBedrooms\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFull Baths\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m X_train_selected \u001b[39m=\u001b[39m X_train[selected_features]\n\u001b[1;32m      8\u001b[0m X_test_selected \u001b[39m=\u001b[39m X_test[selected_features]\n\u001b[1;32m     10\u001b[0m \u001b[39m# Create a Random Forest Regressor object\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Select top 10 features\n",
    "selected_features = ['Area Finished Above Grade', 'Attic_NO ATTIC', 'Neighborhood', 'Zip Code', 'Year Built', \n",
    "                     'Heat and A/C_HEAT/AIR CON', 'Year Remodel', 'Grade_C', 'Bedrooms', 'Full Baths']\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Create a Random Forest Regressor object\n",
    "rf_selected = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model using the training sets\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_selected = rf_selected.predict(X_test_selected)\n",
    "\n",
    "# Calculate the root mean square error\n",
    "rmse_selected = np.sqrt(metrics.mean_squared_error(y_test, y_pred_selected))\n",
    "\n",
    "rmse_selected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not great.  Let's try gradient boosting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create a Gradient Boosting Regressor object\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model using the training sets\n",
    "gbr.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_gbr = gbr.predict(X_test_selected)\n",
    "\n",
    "# Calculate the root mean square error\n",
    "rmse_gbr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_gbr))\n",
    "\n",
    "rmse_gbr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xg Boost will be the next model to try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming `X` and `y` are your features and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "# Adjustable parameters\n",
    "num_neurons_layer1 = 2\n",
    "num_neurons_layer2 = 4\n",
    "num_neurons_layer3 = 8\n",
    "num_neurons_layer4 = 16\n",
    "num_neurons_layer5 = 32\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.9\n",
    "patience = 5\n",
    "l2_reg = 0.0001\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer and a hidden layer with num_neurons_layer1 neurons\n",
    "model.add(Dense(num_neurons_layer1, activation='relu', kernel_regularizer=regularizers.l2(l2_reg), input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Add a second hidden layer with num_neurons_layer2 neurons\n",
    "model.add(Dense(num_neurons_layer2, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Add a third hidden layer with num_neurons_layer3 neurons\n",
    "model.add(Dense(num_neurons_layer3, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Add a fourth hidden layer with num_neurons_layer4 neurons\n",
    "model.add(Dense(num_neurons_layer4, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Add a fifth hidden layer with num_neurons_layer5 neurons\n",
    "model.add(Dense(num_neurons_layer5, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=num_epochs, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# ... rest of your code\n",
    "\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_nn = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the root mean square error\n",
    "rmse_nn = np.sqrt(metrics.mean_squared_error(y_test, y_pred_nn))\n",
    "\n",
    "print(f'Root Mean Square Error: {rmse_nn}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
